---
title: Golang å®ç° RAG ç³»ç»Ÿ ä» OpenAI API åˆ°å‘é‡æ•°æ®åº“å®Œæ•´å®æˆ˜
date: 2025-11-11
author: PFinalå—ä¸
tags:
  - Golang
  - AI
  - RAG
  - LLM
  - Vector Database
  - OpenAI
description: æ·±å…¥è®²è§£å¦‚ä½•ä½¿ç”¨ Golang æ„å»ºå®Œæ•´çš„ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿï¼Œæ¶µç›– OpenAI API é›†æˆã€å‘é‡æ•°æ®åº“é€‰å‹ã€Embedding ç”Ÿæˆã€è¯­ä¹‰æ£€ç´¢å’Œå®æˆ˜æ¡ˆä¾‹ï¼ŒåŠ©åŠ›å¼€å‘è€…å¿«é€Ÿæ„å»ºæ™ºèƒ½é—®ç­”ç³»ç»Ÿã€‚
keywords: Golang RAG, RAGç³»ç»Ÿ, å‘é‡æ•°æ®åº“, OpenAI API, Embedding, è¯­ä¹‰æ£€ç´¢, LLM, Golang AI, æ™ºèƒ½é—®ç­”, Retrieval-Augmented Generation
---

# Golang å®ç° RAG ç³»ç»Ÿï¼šä» OpenAI API åˆ°å‘é‡æ•°æ®åº“å®Œæ•´å®æˆ˜

## ğŸ“– å¼•è¨€

RAGï¼ˆRetrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ˜¯ 2024-2025 å¹´æœ€çƒ­é—¨çš„ AI åº”ç”¨æ¶æ„ä¹‹ä¸€ã€‚å®ƒé€šè¿‡ç»“åˆå¤–éƒ¨çŸ¥è¯†åº“æ£€ç´¢å’Œå¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆèƒ½åŠ›ï¼Œæœ‰æ•ˆè§£å†³äº† LLM çš„å¹»è§‰é—®é¢˜å’ŒçŸ¥è¯†æ—¶æ•ˆæ€§é™åˆ¶ã€‚

æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨ Golang æ„å»ºä¸€ä¸ªå®Œæ•´çš„ RAG ç³»ç»Ÿï¼ŒåŒ…æ‹¬ï¼š
- ğŸ” æ–‡æ¡£å¤„ç†ä¸ Chunking ç­–ç•¥
- ğŸ§  å‘é‡åŒ–ï¼ˆEmbeddingï¼‰å®ç°
- ğŸ“Š å‘é‡æ•°æ®åº“é›†æˆï¼ˆQdrantï¼‰
- ğŸ” è¯­ä¹‰æ£€ç´¢ä¼˜åŒ–
- ğŸ’¬ ä¸ OpenAI API é›†æˆç”Ÿæˆå›ç­”
- ğŸš€ ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

## ğŸ¯ ä»€ä¹ˆæ˜¯ RAGï¼Ÿ

### RAG å·¥ä½œåŸç†

```
ç”¨æˆ·é—®é¢˜ â†’ å‘é‡åŒ– â†’ è¯­ä¹‰æ£€ç´¢ â†’ å¬å›ç›¸å…³æ–‡æ¡£ â†’ æ„å»º Prompt â†’ LLM ç”Ÿæˆç­”æ¡ˆ
```

### RAG vs ä¼ ç»Ÿ LLM

| ç‰¹æ€§ | ä¼ ç»Ÿ LLM | RAG ç³»ç»Ÿ |
|------|----------|----------|
| çŸ¥è¯†æ¥æº | è®­ç»ƒæ•°æ®ï¼ˆé™æ€ï¼‰ | å¤–éƒ¨çŸ¥è¯†åº“ï¼ˆåŠ¨æ€ï¼‰ |
| æ—¶æ•ˆæ€§ | å·®ï¼ˆè®­ç»ƒæ—¶é—´ç‚¹ï¼‰ | å¥½ï¼ˆå®æ—¶æ›´æ–°ï¼‰ |
| å¹»è§‰é—®é¢˜ | ä¸¥é‡ | æ˜¾è‘—é™ä½ |
| æˆæœ¬ | é«˜ï¼ˆéœ€è¦å¤§é‡ tokensï¼‰ | ä¸­ç­‰ï¼ˆä»…æ£€ç´¢ç›¸å…³å†…å®¹ï¼‰ |
| å¯è¿½æº¯æ€§ | æ—  | æœ‰ï¼ˆå¯å¼•ç”¨æ¥æºï¼‰ |

## ğŸ› ï¸ æŠ€æœ¯æ ˆé€‰å‹

### æ ¸å¿ƒç»„ä»¶

```go
// æˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹æŠ€æœ¯æ ˆ
- Go 1.21+               // ä¸»å¼€å‘è¯­è¨€
- OpenAI API (gpt-4)     // LLM æœåŠ¡
- text-embedding-ada-002 // Embedding æ¨¡å‹
- Qdrant                 // å‘é‡æ•°æ®åº“
- gin                    // Web æ¡†æ¶
- go-openai              // OpenAI Go SDK
```

### ä¸ºä»€ä¹ˆé€‰æ‹© Golangï¼Ÿ

1. **é«˜æ€§èƒ½**ï¼šå¹¶å‘å¤„ç†å¤§é‡æ–‡æ¡£
2. **ç®€å•éƒ¨ç½²**ï¼šå•äºŒè¿›åˆ¶æ–‡ä»¶
3. **ä¼˜ç§€çš„å¹¶å‘æ¨¡å‹**ï¼šgoroutine å¤„ç†å¹¶è¡Œä»»åŠ¡
4. **ä¸°å¯Œçš„ç”Ÿæ€**ï¼šAI ç›¸å…³åº“é€æ¸æˆç†Ÿ

## ğŸ“¦ ç¯å¢ƒå‡†å¤‡

### 1. å®‰è£…ä¾èµ–

```bash
# åˆå§‹åŒ–é¡¹ç›®
mkdir golang-rag-system
cd golang-rag-system
go mod init github.com/yourusername/golang-rag

# å®‰è£…æ ¸å¿ƒä¾èµ–
go get github.com/sashabaranov/go-openai
go get github.com/qdrant/go-client
go get github.com/gin-gonic/gin
go get github.com/joho/godotenv
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

```bash
# .env
OPENAI_API_KEY=sk-xxxxxxxxxx
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=your-qdrant-key
COLLECTION_NAME=documents
```

### 3. å¯åŠ¨ Qdrantï¼ˆä½¿ç”¨ Dockerï¼‰

```bash
docker run -p 6333:6333 -p 6334:6334 \
  -v $(pwd)/qdrant_storage:/qdrant/storage:z \
  qdrant/qdrant
```

## ğŸ’» æ ¸å¿ƒå®ç°

### 1. é¡¹ç›®ç»“æ„

```
golang-rag/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ main.go           # å…¥å£æ–‡ä»¶
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ embedding/        # Embedding ç”Ÿæˆ
â”‚   â”‚   â””â”€â”€ openai.go
â”‚   â”œâ”€â”€ vectordb/         # å‘é‡æ•°æ®åº“æ“ä½œ
â”‚   â”‚   â””â”€â”€ qdrant.go
â”‚   â”œâ”€â”€ chunker/          # æ–‡æ¡£åˆ†å—
â”‚   â”‚   â””â”€â”€ text_splitter.go
â”‚   â”œâ”€â”€ retriever/        # æ£€ç´¢å™¨
â”‚   â”‚   â””â”€â”€ retriever.go
â”‚   â””â”€â”€ rag/              # RAG æ ¸å¿ƒé€»è¾‘
â”‚       â””â”€â”€ pipeline.go
â”œâ”€â”€ pkg/
â”‚   â””â”€â”€ models/           # æ•°æ®æ¨¡å‹
â”‚       â””â”€â”€ document.go
â”œâ”€â”€ .env
â”œâ”€â”€ go.mod
â””â”€â”€ go.sum
```

### 2. æ•°æ®æ¨¡å‹å®šä¹‰

```go
// pkg/models/document.go
package models

type Document struct {
    ID        string                 `json:"id"`
    Content   string                 `json:"content"`
    Metadata  map[string]interface{} `json:"metadata"`
    Embedding []float32              `json:"embedding,omitempty"`
}

type SearchResult struct {
    Document Document  `json:"document"`
    Score    float64   `json:"score"`
}

type RAGResponse struct {
    Answer    string         `json:"answer"`
    Sources   []SearchResult `json:"sources"`
    TokenUsed int            `json:"token_used"`
}
```

### 3. Embedding ç”Ÿæˆå™¨

```go
// internal/embedding/openai.go
package embedding

import (
    "context"
    "fmt"
    "github.com/sashabaranov/go-openai"
)

type EmbeddingService struct {
    client *openai.Client
    model  string
}

func NewEmbeddingService(apiKey string) *EmbeddingService {
    return &EmbeddingService{
        client: openai.NewClient(apiKey),
        model:  openai.AdaEmbeddingV2,
    }
}

// GenerateEmbedding ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„å‘é‡
func (s *EmbeddingService) GenerateEmbedding(ctx context.Context, text string) ([]float32, error) {
    req := openai.EmbeddingRequest{
        Input: []string{text},
        Model: s.model,
    }

    resp, err := s.client.CreateEmbeddings(ctx, req)
    if err != nil {
        return nil, fmt.Errorf("failed to create embedding: %w", err)
    }

    if len(resp.Data) == 0 {
        return nil, fmt.Errorf("no embedding data returned")
    }

    return resp.Data[0].Embedding, nil
}

// BatchGenerateEmbeddings æ‰¹é‡ç”Ÿæˆå‘é‡ï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰
func (s *EmbeddingService) BatchGenerateEmbeddings(ctx context.Context, texts []string) ([][]float32, error) {
    // OpenAI å•æ¬¡æœ€å¤šæ”¯æŒ 2048 ä¸ªè¾“å…¥
    const batchSize = 100
    var allEmbeddings [][]float32

    for i := 0; i < len(texts); i += batchSize {
        end := i + batchSize
        if end > len(texts) {
            end = len(texts)
        }

        batch := texts[i:end]
        req := openai.EmbeddingRequest{
            Input: batch,
            Model: s.model,
        }

        resp, err := s.client.CreateEmbeddings(ctx, req)
        if err != nil {
            return nil, fmt.Errorf("batch embedding failed: %w", err)
        }

        for _, data := range resp.Data {
            allEmbeddings = append(allEmbeddings, data.Embedding)
        }
    }

    return allEmbeddings, nil
}
```

### 4. æ–‡æ¡£åˆ†å—å™¨

```go
// internal/chunker/text_splitter.go
package chunker

import (
    "strings"
    "unicode/utf8"
)

type TextSplitter struct {
    ChunkSize    int     // æ¯å—å­—ç¬¦æ•°
    ChunkOverlap int     // é‡å å­—ç¬¦æ•°
}

func NewTextSplitter(chunkSize, overlap int) *TextSplitter {
    return &TextSplitter{
        ChunkSize:    chunkSize,
        ChunkOverlap: overlap,
    }
}

// SplitText å°†é•¿æ–‡æœ¬åˆ†å‰²æˆå¤šä¸ª chunk
func (ts *TextSplitter) SplitText(text string) []string {
    if utf8.RuneCountInString(text) <= ts.ChunkSize {
        return []string{text}
    }

    var chunks []string
    runes := []rune(text)
    start := 0

    for start < len(runes) {
        end := start + ts.ChunkSize
        if end > len(runes) {
            end = len(runes)
        }

        // å°è¯•åœ¨å¥å­è¾¹ç•Œåˆ†å‰²
        if end < len(runes) {
            // æŸ¥æ‰¾æœ€è¿‘çš„å¥å·ã€é—®å·æˆ–æ¢è¡Œç¬¦
            for i := end; i > start+ts.ChunkSize/2; i-- {
                if runes[i] == 'ã€‚' || runes[i] == 'ï¼Ÿ' || runes[i] == '\n' || runes[i] == '.' {
                    end = i + 1
                    break
                }
            }
        }

        chunk := string(runes[start:end])
        chunks = append(chunks, strings.TrimSpace(chunk))

        // è®¡ç®—ä¸‹ä¸€ä¸ªèµ·å§‹ä½ç½®ï¼ˆè€ƒè™‘é‡å ï¼‰
        start = end - ts.ChunkOverlap
        if start < 0 {
            start = 0
        }
    }

    return chunks
}

// SplitByParagraph æŒ‰æ®µè½åˆ†å‰²ï¼ˆé€‚ç”¨äºç»“æ„åŒ–æ–‡æ¡£ï¼‰
func (ts *TextSplitter) SplitByParagraph(text string) []string {
    paragraphs := strings.Split(text, "\n\n")
    var chunks []string

    currentChunk := ""
    for _, para := range paragraphs {
        para = strings.TrimSpace(para)
        if para == "" {
            continue
        }

        if utf8.RuneCountInString(currentChunk+para) <= ts.ChunkSize {
            if currentChunk != "" {
                currentChunk += "\n\n"
            }
            currentChunk += para
        } else {
            if currentChunk != "" {
                chunks = append(chunks, currentChunk)
            }
            // å¦‚æœå•ä¸ªæ®µè½è¶…è¿‡ ChunkSizeï¼Œè¿›ä¸€æ­¥åˆ†å‰²
            if utf8.RuneCountInString(para) > ts.ChunkSize {
                chunks = append(chunks, ts.SplitText(para)...)
            } else {
                currentChunk = para
            }
        }
    }

    if currentChunk != "" {
        chunks = append(chunks, currentChunk)
    }

    return chunks
}
```

### 5. å‘é‡æ•°æ®åº“æ“ä½œ

```go
// internal/vectordb/qdrant.go
package vectordb

import (
    "context"
    "fmt"
    "github.com/google/uuid"
    pb "github.com/qdrant/go-client/qdrant"
    "google.golang.org/grpc"
    "google.golang.org/grpc/credentials/insecure"
    "your-project/pkg/models"
)

type QdrantClient struct {
    client         pb.PointsClient
    collectionName string
}

func NewQdrantClient(address, collectionName string) (*QdrantClient, error) {
    conn, err := grpc.Dial(address, grpc.WithTransportCredentials(insecure.NewCredentials()))
    if err != nil {
        return nil, fmt.Errorf("failed to connect to Qdrant: %w", err)
    }

    return &QdrantClient{
        client:         pb.NewPointsClient(conn),
        collectionName: collectionName,
    }, nil
}

// UpsertDocuments æ’å…¥æˆ–æ›´æ–°æ–‡æ¡£
func (q *QdrantClient) UpsertDocuments(ctx context.Context, docs []models.Document) error {
    points := make([]*pb.PointStruct, 0, len(docs))

    for _, doc := range docs {
        if doc.ID == "" {
            doc.ID = uuid.New().String()
        }

        // è½¬æ¢ metadata ä¸º payload
        payload := make(map[string]*pb.Value)
        payload["content"] = &pb.Value{
            Kind: &pb.Value_StringValue{StringValue: doc.Content},
        }

        for k, v := range doc.Metadata {
            if strVal, ok := v.(string); ok {
                payload[k] = &pb.Value{
                    Kind: &pb.Value_StringValue{StringValue: strVal},
                }
            }
        }

        point := &pb.PointStruct{
            Id: &pb.PointId{
                PointIdOptions: &pb.PointId_Uuid{Uuid: doc.ID},
            },
            Vectors: &pb.Vectors{
                VectorsOptions: &pb.Vectors_Vector{
                    Vector: &pb.Vector{Data: doc.Embedding},
                },
            },
            Payload: payload,
        }

        points = append(points, point)
    }

    _, err := q.client.Upsert(ctx, &pb.UpsertPoints{
        CollectionName: q.collectionName,
        Points:         points,
    })

    return err
}

// Search è¯­ä¹‰æœç´¢
func (q *QdrantClient) Search(ctx context.Context, queryVector []float32, topK int) ([]models.SearchResult, error) {
    resp, err := q.client.Search(ctx, &pb.SearchPoints{
        CollectionName: q.collectionName,
        Vector:         queryVector,
        Limit:          uint64(topK),
        WithPayload:    &pb.WithPayloadSelector{SelectorOptions: &pb.WithPayloadSelector_Enable{Enable: true}},
    })

    if err != nil {
        return nil, fmt.Errorf("search failed: %w", err)
    }

    results := make([]models.SearchResult, 0, len(resp.Result))
    for _, point := range resp.Result {
        content := ""
        metadata := make(map[string]interface{})

        if payload := point.Payload; payload != nil {
            if contentVal, ok := payload["content"]; ok {
                if strVal := contentVal.GetStringValue(); strVal != "" {
                    content = strVal
                }
            }

            for k, v := range payload {
                if k != "content" {
                    if strVal := v.GetStringValue(); strVal != "" {
                        metadata[k] = strVal
                    }
                }
            }
        }

        results = append(results, models.SearchResult{
            Document: models.Document{
                ID:       point.Id.GetUuid(),
                Content:  content,
                Metadata: metadata,
            },
            Score: float64(point.Score),
        })
    }

    return results, nil
}
```

### 6. RAG æ ¸å¿ƒç®¡é“

```go
// internal/rag/pipeline.go
package rag

import (
    "context"
    "fmt"
    "strings"
    "github.com/sashabaranov/go-openai"
    "your-project/internal/embedding"
    "your-project/internal/vectordb"
    "your-project/pkg/models"
)

type RAGPipeline struct {
    embeddingService *embedding.EmbeddingService
    vectorDB         *vectordb.QdrantClient
    llmClient        *openai.Client
    topK             int
}

func NewRAGPipeline(
    embService *embedding.EmbeddingService,
    vdb *vectordb.QdrantClient,
    openaiKey string,
    topK int,
) *RAGPipeline {
    return &RAGPipeline{
        embeddingService: embService,
        vectorDB:         vdb,
        llmClient:        openai.NewClient(openaiKey),
        topK:             topK,
    }
}

// Query æ‰§è¡Œ RAG æŸ¥è¯¢
func (r *RAGPipeline) Query(ctx context.Context, question string) (*models.RAGResponse, error) {
    // 1. å°†é—®é¢˜å‘é‡åŒ–
    queryVector, err := r.embeddingService.GenerateEmbedding(ctx, question)
    if err != nil {
        return nil, fmt.Errorf("failed to generate query embedding: %w", err)
    }

    // 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
    searchResults, err := r.vectorDB.Search(ctx, queryVector, r.topK)
    if err != nil {
        return nil, fmt.Errorf("failed to search documents: %w", err)
    }

    if len(searchResults) == 0 {
        return &models.RAGResponse{
            Answer:  "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚",
            Sources: []models.SearchResult{},
        }, nil
    }

    // 3. æ„å»ºä¸Šä¸‹æ–‡
    context := r.buildContext(searchResults)

    // 4. è°ƒç”¨ LLM ç”Ÿæˆå›ç­”
    answer, tokenUsed, err := r.generateAnswer(ctx, question, context)
    if err != nil {
        return nil, fmt.Errorf("failed to generate answer: %w", err)
    }

    return &models.RAGResponse{
        Answer:    answer,
        Sources:   searchResults,
        TokenUsed: tokenUsed,
    }, nil
}

// buildContext æ„å»ºä¸Šä¸‹æ–‡æç¤ºè¯
func (r *RAGPipeline) buildContext(results []models.SearchResult) string {
    var sb strings.Builder
    sb.WriteString("ä»¥ä¸‹æ˜¯ç›¸å…³çš„å‚è€ƒä¿¡æ¯ï¼š\n\n")

    for i, result := range results {
        sb.WriteString(fmt.Sprintf("ã€å‚è€ƒ %dã€‘\n%s\n\n", i+1, result.Document.Content))
    }

    return sb.String()
}

// generateAnswer è°ƒç”¨ LLM ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
func (r *RAGPipeline) generateAnswer(ctx context.Context, question, context string) (string, int, error) {
    prompt := fmt.Sprintf(`ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹å‚è€ƒä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

%s

ç”¨æˆ·é—®é¢˜ï¼š%s

è¯·æ³¨æ„ï¼š
1. ä»…åŸºäºå‚è€ƒä¿¡æ¯å›ç­”ï¼Œä¸è¦ç¼–é€ å†…å®¹
2. å¦‚æœå‚è€ƒä¿¡æ¯ä¸è¶³ï¼Œè¯·æ˜ç¡®è¯´æ˜
3. å›ç­”è¦å‡†ç¡®ã€ä¸“ä¸šã€æ˜“æ‡‚
4. å¯ä»¥å¼•ç”¨å‚è€ƒä¿¡æ¯çš„ç¼–å·

ä½ çš„å›ç­”ï¼š`, context, question)

    req := openai.ChatCompletionRequest{
        Model: openai.GPT4TurboPreview,
        Messages: []openai.ChatCompletionMessage{
            {
                Role:    openai.ChatMessageRoleSystem,
                Content: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åŠ©æ‰‹ï¼Œæ“…é•¿åŸºäºæä¾›çš„å‚è€ƒèµ„æ–™å‡†ç¡®å›ç­”é—®é¢˜ã€‚",
            },
            {
                Role:    openai.ChatMessageRoleUser,
                Content: prompt,
            },
        },
        Temperature: 0.7,
        MaxTokens:   1000,
    }

    resp, err := r.llmClient.CreateChatCompletion(ctx, req)
    if err != nil {
        return "", 0, err
    }

    if len(resp.Choices) == 0 {
        return "", 0, fmt.Errorf("no response from LLM")
    }

    return resp.Choices[0].Message.Content, resp.Usage.TotalTokens, nil
}
```

### 7. HTTP API æ¥å£

```go
// cmd/main.go
package main

import (
    "context"
    "log"
    "net/http"
    "os"

    "github.com/gin-gonic/gin"
    "github.com/joho/godotenv"
    "your-project/internal/chunker"
    "your-project/internal/embedding"
    "your-project/internal/rag"
    "your-project/internal/vectordb"
    "your-project/pkg/models"
)

type Server struct {
    ragPipeline *rag.RAGPipeline
    embService  *embedding.EmbeddingService
    vectorDB    *vectordb.QdrantClient
    chunker     *chunker.TextSplitter
}

func main() {
    // åŠ è½½ç¯å¢ƒå˜é‡
    if err := godotenv.Load(); err != nil {
        log.Println("Warning: .env file not found")
    }

    // åˆå§‹åŒ–æœåŠ¡
    embService := embedding.NewEmbeddingService(os.Getenv("OPENAI_API_KEY"))
    
    vectorDB, err := vectordb.NewQdrantClient(
        os.Getenv("QDRANT_URL"),
        os.Getenv("COLLECTION_NAME"),
    )
    if err != nil {
        log.Fatal("Failed to connect to Qdrant:", err)
    }

    ragPipeline := rag.NewRAGPipeline(embService, vectorDB, os.Getenv("OPENAI_API_KEY"), 5)
    textSplitter := chunker.NewTextSplitter(500, 50)

    server := &Server{
        ragPipeline: ragPipeline,
        embService:  embService,
        vectorDB:    vectorDB,
        chunker:     textSplitter,
    }

    // è®¾ç½®è·¯ç”±
    r := gin.Default()
    
    r.POST("/ingest", server.handleIngest)
    r.POST("/query", server.handleQuery)
    r.GET("/health", func(c *gin.Context) {
        c.JSON(http.StatusOK, gin.H{"status": "healthy"})
    })

    log.Println("Server starting on :8080")
    if err := r.Run(":8080"); err != nil {
        log.Fatal("Failed to start server:", err)
    }
}

// handleIngest å¤„ç†æ–‡æ¡£å¯¼å…¥
func (s *Server) handleIngest(c *gin.Context) {
    var req struct {
        Text     string                 `json:"text" binding:"required"`
        Metadata map[string]interface{} `json:"metadata"`
    }

    if err := c.ShouldBindJSON(&req); err != nil {
        c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
        return
    }

    ctx := context.Background()

    // 1. åˆ†å—
    chunks := s.chunker.SplitText(req.Text)

    // 2. ç”Ÿæˆå‘é‡
    embeddings, err := s.embService.BatchGenerateEmbeddings(ctx, chunks)
    if err != nil {
        c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to generate embeddings"})
        return
    }

    // 3. æ„å»ºæ–‡æ¡£
    docs := make([]models.Document, len(chunks))
    for i, chunk := range chunks {
        docs[i] = models.Document{
            Content:   chunk,
            Metadata:  req.Metadata,
            Embedding: embeddings[i],
        }
    }

    // 4. å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
    if err := s.vectorDB.UpsertDocuments(ctx, docs); err != nil {
        c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to store documents"})
        return
    }

    c.JSON(http.StatusOK, gin.H{
        "message":    "Documents ingested successfully",
        "chunk_count": len(chunks),
    })
}

// handleQuery å¤„ç†æŸ¥è¯¢è¯·æ±‚
func (s *Server) handleQuery(c *gin.Context) {
    var req struct {
        Question string `json:"question" binding:"required"`
    }

    if err := c.ShouldBindJSON(&req); err != nil {
        c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
        return
    }

    ctx := context.Background()
    response, err := s.ragPipeline.Query(ctx, req.Question)
    if err != nil {
        c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
        return
    }

    c.JSON(http.StatusOK, response)
}
```

## ğŸ§ª æµ‹è¯•ä¸ä½¿ç”¨

### 1. å¯¼å…¥æ–‡æ¡£

```bash
curl -X POST http://localhost:8080/ingest \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Golang æ˜¯ä¸€é—¨ç”± Google å¼€å‘çš„å¼€æºç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•ã€å‡ºè‰²çš„å¹¶å‘æ€§èƒ½å’Œå¿«é€Ÿçš„ç¼–è¯‘é€Ÿåº¦è€Œé—»åã€‚Go è¯­è¨€ç‰¹åˆ«é€‚åˆæ„å»ºé«˜æ€§èƒ½çš„æœåŠ¡å™¨ç«¯åº”ç”¨ã€å¾®æœåŠ¡æ¶æ„å’Œäº‘åŸç”Ÿåº”ç”¨ã€‚",
    "metadata": {
      "source": "golang-introduction",
      "category": "programming-language"
    }
  }'
```

### 2. æŸ¥è¯¢é—®é¢˜

```bash
curl -X POST http://localhost:8080/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Golang æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ"
  }'
```

### å“åº”ç¤ºä¾‹

```json
{
  "answer": "åŸºäºå‚è€ƒä¿¡æ¯ï¼ŒGolang çš„ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ï¼š\n1. ç®€æ´çš„è¯­æ³•\n2. å‡ºè‰²çš„å¹¶å‘æ€§èƒ½\n3. å¿«é€Ÿçš„ç¼–è¯‘é€Ÿåº¦\n4. ç‰¹åˆ«é€‚åˆæ„å»ºé«˜æ€§èƒ½æœåŠ¡å™¨ç«¯åº”ç”¨ã€å¾®æœåŠ¡æ¶æ„å’Œäº‘åŸç”Ÿåº”ç”¨",
  "sources": [
    {
      "document": {
        "id": "xxx-xxx-xxx",
        "content": "Golang æ˜¯ä¸€é—¨ç”± Google å¼€å‘çš„...",
        "metadata": {
          "source": "golang-introduction"
        }
      },
      "score": 0.89
    }
  ],
  "token_used": 245
}
```

## ğŸš€ ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–

### 1. æ€§èƒ½ä¼˜åŒ–

#### ä½¿ç”¨è¿æ¥æ± 

```go
// ä¸º OpenAI API é…ç½® HTTP å®¢æˆ·ç«¯è¿æ¥æ± 
httpClient := &http.Client{
    Timeout: 30 * time.Second,
    Transport: &http.Transport{
        MaxIdleConns:        100,
        MaxIdleConnsPerHost: 10,
        IdleConnTimeout:     90 * time.Second,
    },
}

config := openai.DefaultConfig(apiKey)
config.HTTPClient = httpClient
client := openai.NewClientWithConfig(config)
```

#### ç¼“å­˜ Embedding

```go
// ä½¿ç”¨ Redis ç¼“å­˜å¸¸è§æŸ¥è¯¢çš„ embedding
type CachedEmbeddingService struct {
    embService *embedding.EmbeddingService
    cache      *redis.Client
    ttl        time.Duration
}

func (c *CachedEmbeddingService) GetEmbedding(ctx context.Context, text string) ([]float32, error) {
    // ç”Ÿæˆç¼“å­˜ key
    key := fmt.Sprintf("emb:%s", hashText(text))
    
    // å°è¯•ä»ç¼“å­˜è·å–
    cached, err := c.cache.Get(ctx, key).Bytes()
    if err == nil {
        return deserializeEmbedding(cached), nil
    }
    
    // ç¼“å­˜æœªå‘½ä¸­ï¼Œç”Ÿæˆæ–°çš„ embedding
    emb, err := c.embService.GenerateEmbedding(ctx, text)
    if err != nil {
        return nil, err
    }
    
    // å­˜å…¥ç¼“å­˜
    c.cache.Set(ctx, key, serializeEmbedding(emb), c.ttl)
    return emb, nil
}
```

### 2. å¯è§‚æµ‹æ€§

#### æ·»åŠ æ—¥å¿—å’ŒæŒ‡æ ‡

```go
import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    queryDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "rag_query_duration_seconds",
            Help: "RAG query duration in seconds",
        },
        []string{"status"},
    )

    embeddingRequests = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "embedding_requests_total",
            Help: "Total number of embedding requests",
        },
        []string{"status"},
    )
)

func (r *RAGPipeline) Query(ctx context.Context, question string) (*models.RAGResponse, error) {
    start := time.Now()
    defer func() {
        duration := time.Since(start).Seconds()
        queryDuration.WithLabelValues("success").Observe(duration)
    }()

    // ... åŸæœ‰é€»è¾‘
}
```

### 3. é”™è¯¯å¤„ç†ä¸é‡è¯•

```go
import "github.com/cenkalti/backoff/v4"

func (s *EmbeddingService) GenerateEmbeddingWithRetry(ctx context.Context, text string) ([]float32, error) {
    var result []float32
    
    operation := func() error {
        var err error
        result, err = s.GenerateEmbedding(ctx, text)
        return err
    }

    // æŒ‡æ•°é€€é¿é‡è¯•ç­–ç•¥
    expBackoff := backoff.NewExponentialBackOff()
    expBackoff.MaxElapsedTime = 30 * time.Second

    err := backoff.Retry(operation, expBackoff)
    return result, err
}
```

## ğŸ“Š è¿›é˜¶æŠ€å·§

### 1. æ··åˆæ£€ç´¢ï¼ˆHybrid Searchï¼‰

ç»“åˆå…³é”®è¯æ£€ç´¢å’Œè¯­ä¹‰æ£€ç´¢ï¼š

```go
type HybridRetriever struct {
    vectorDB    *vectordb.QdrantClient
    keywordDB   *ElasticsearchClient
    vectorWeight float64  // 0-1ï¼Œå‘é‡æ£€ç´¢æƒé‡
}

func (h *HybridRetriever) Search(ctx context.Context, query string, topK int) ([]models.SearchResult, error) {
    // 1. å¹¶è¡Œæ‰§è¡Œä¸¤ç§æ£€ç´¢
    var vectorResults, keywordResults []models.SearchResult
    var wg sync.WaitGroup
    wg.Add(2)

    go func() {
        defer wg.Done()
        vectorResults, _ = h.vectorDB.Search(ctx, queryVector, topK)
    }()

    go func() {
        defer wg.Done()
        keywordResults, _ = h.keywordDB.Search(ctx, query, topK)
    }()

    wg.Wait()

    // 2. èåˆç»“æœï¼ˆRRF - Reciprocal Rank Fusionï¼‰
    return h.fuseResults(vectorResults, keywordResults), nil
}
```

### 2. ReRank é‡æ’åº

ä½¿ç”¨ Cohere ReRank API æˆ–æœ¬åœ°æ¨¡å‹æå‡æ£€ç´¢ç²¾åº¦ï¼š

```go
func (r *RAGPipeline) ReRank(ctx context.Context, query string, docs []models.Document) ([]models.Document, error) {
    // è°ƒç”¨ Cohere ReRank API
    client := cohere.NewClient(os.Getenv("COHERE_API_KEY"))
    
    response, err := client.Rerank(ctx, &cohere.RerankRequest{
        Query:     query,
        Documents: extractContents(docs),
        TopN:      5,
        Model:     "rerank-multilingual-v2.0",
    })
    
    if err != nil {
        return nil, err
    }

    // æ ¹æ® ReRank åˆ†æ•°é‡æ–°æ’åº
    reranked := make([]models.Document, len(response.Results))
    for i, result := range response.Results {
        reranked[i] = docs[result.Index]
    }

    return reranked, nil
}
```

### 3. å¤šæ¨¡æ€ RAG

æ”¯æŒå›¾ç‰‡ã€è¡¨æ ¼ç­‰å¤šæ¨¡æ€å†…å®¹ï¼š

```go
// ä½¿ç”¨ GPT-4 Vision æå–å›¾ç‰‡å†…å®¹
func (s *MultiModalService) ExtractImageContent(ctx context.Context, imageURL string) (string, error) {
    req := openai.ChatCompletionRequest{
        Model: openai.GPT4VisionPreview,
        Messages: []openai.ChatCompletionMessage{
            {
                Role: openai.ChatMessageRoleUser,
                MultiContent: []openai.ChatMessagePart{
                    {
                        Type: openai.ChatMessagePartTypeText,
                        Text: "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡ä¸­çš„å†…å®¹ï¼ŒåŒ…æ‹¬æ–‡å­—ã€å›¾è¡¨ã€å…³é”®ä¿¡æ¯ç­‰ã€‚",
                    },
                    {
                        Type: openai.ChatMessagePartTypeImageURL,
                        ImageURL: &openai.ChatMessageImageURL{
                            URL: imageURL,
                        },
                    },
                },
            },
        },
    }

    resp, err := s.client.CreateChatCompletion(ctx, req)
    // ... å¤„ç†å“åº”
}
```

## ğŸš¨ æˆ‘åœ¨å¼€å‘ä¸­è¸©è¿‡çš„ 5 ä¸ªå‘

åœ¨å®é™…æ„å»º RAG ç³»ç»Ÿçš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘è¸©äº†ä¸å°‘å‘ã€‚è¿™é‡Œåˆ†äº«å‡ ä¸ªæœ€å…¸å‹çš„ï¼Œå¸Œæœ›èƒ½å¸®ä½ å°‘èµ°å¼¯è·¯ã€‚

### å‘ 1ï¼šQdrant è¿æ¥ä¸€ç›´è¶…æ—¶

**ç°è±¡**ï¼š  
æœ¬åœ°å¼€å‘æ—¶ï¼ŒQdrant è¿æ¥æ­£å¸¸ï¼›  
ä½†ä¸€æŠŠé¡¹ç›®æ‰“åŒ…æˆ Docker é•œåƒéƒ¨ç½²ï¼Œå°±æ­»æ´»è¿ä¸ä¸Š Qdrantã€‚

**æ’æŸ¥è¿‡ç¨‹**ï¼š
```bash
# åœ¨å®¹å™¨é‡Œ ping Qdrant
$ docker exec -it rag-service ping qdrant
ping: unknown host qdrant

# åŸæ¥æ˜¯ docker network æ²¡é…ç½®å¯¹
```

**åŸå› **ï¼š  
æˆ‘åœ¨ `docker-compose.yml` é‡ŒæŠŠ Qdrant å’Œ RAG æœåŠ¡æ”¾åœ¨äº†ä¸åŒçš„ networkï¼Œå¯¼è‡´å®¹å™¨é—´æ— æ³•é€šä¿¡ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```yaml
# docker-compose.ymlï¼ˆæ­£ç¡®ç‰ˆæœ¬ï¼‰
version: '3.8'
services:
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
    networks:
      - rag-network
  
  rag-service:
    build: .
    environment:
      QDRANT_URL: "http://qdrant:6333"  # ç”¨æœåŠ¡åï¼Œä¸æ˜¯ localhost
    networks:
      - rag-network

networks:
  rag-network:
    driver: bridge
```

**æ•™è®­**ï¼š  
å®¹å™¨åŒ–ç¯å¢ƒä¸‹ï¼ŒæœåŠ¡é—´é€šä¿¡è¦ç”¨ **æœåŠ¡å** è€Œä¸æ˜¯ `localhost`ã€‚

---

### å‘ 2ï¼šEmbedding ç»´åº¦ä¸åŒ¹é…ï¼Œæ’å…¥å‘é‡æŠ¥é”™

**ç°è±¡**ï¼š
```go
// æ’å…¥å‘é‡åˆ° Qdrant æ—¶æŠ¥é”™
err := client.Upsert(ctx, &qdrant.UpsertPoints{...})
// Error: dimension mismatch: expected 512, got 1536
```

**åŸå› **ï¼š  
æˆ‘åœ¨åˆ›å»º Qdrant collection æ—¶ï¼ŒæŠŠ vector size é…ç½®æˆäº† 512ï¼š

```go
// é”™è¯¯çš„é…ç½®
client.CreateCollection(ctx, &qdrant.CreateCollection{
    CollectionName: "documents",
    VectorsConfig: qdrant.VectorsConfig{
        Params: &qdrant.VectorParams{
            Size:     512,  // âŒ é”™äº†ï¼text-embedding-ada-002 æ˜¯ 1536 ç»´
            Distance: qdrant.Distance_Cosine,
        },
    },
})
```

ä½† OpenAI çš„ `text-embedding-ada-002` æ¨¡å‹è¿”å›çš„å‘é‡æ˜¯ **1536 ç»´**ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```go
// æ­£ç¡®çš„é…ç½®
client.CreateCollection(ctx, &qdrant.CreateCollection{
    CollectionName: "documents",
    VectorsConfig: qdrant.VectorsConfig{
        Params: &qdrant.VectorParams{
            Size:     1536,  // âœ… æ”¹æˆ 1536
            Distance: qdrant.Distance_Cosine,
        },
    },
})
```

**æ•™è®­**ï¼š  
ä¸€å®šè¦å…ˆæŸ¥æ¸…æ¥š Embedding æ¨¡å‹çš„è¾“å‡ºç»´åº¦ï¼Œå†é…ç½®å‘é‡æ•°æ®åº“ã€‚

| æ¨¡å‹ | ç»´åº¦ |
|------|------|
| text-embedding-ada-002 | 1536 |
| text-embedding-3-small | 1536 |
| text-embedding-3-large | 3072 |

ï¼ˆ**è¿™é‡Œåç»­è¡¥ä¸€å¼ æˆªå›¾ï¼šQdrant Web UI æ˜¾ç¤º collection çš„é…ç½®ä¿¡æ¯**ï¼‰

---

### å‘ 3ï¼šæ£€ç´¢ç»“æœå…¨æ˜¯å™ªéŸ³ï¼Œç­”éæ‰€é—®

**ç°è±¡**ï¼š  
ç”¨æˆ·é—®ï¼š"Golang å¦‚ä½•å¤„ç†å¹¶å‘ï¼Ÿ"  
ç³»ç»Ÿè¿”å›çš„å´æ˜¯ï¼š"Python åˆ—è¡¨æ¨å¯¼å¼çš„ç”¨æ³•"ã€‚

**æ’æŸ¥è¿‡ç¨‹**ï¼š  
æˆ‘æ£€æŸ¥äº†æ£€ç´¢å‡ºæ¥çš„ top-5 æ–‡æ¡£ï¼Œå‘ç°åˆ†æ•°éƒ½å¾ˆä½ï¼ˆ0.3 å·¦å³ï¼‰ï¼Œè¯´æ˜ç¡®å®æ²¡åŒ¹é…åˆ°ç›¸å…³å†…å®¹ã€‚

**åŸå› æœ‰ä¸¤ä¸ª**ï¼š

1. **æ–‡æ¡£åˆ‡ç‰‡ï¼ˆChunkingï¼‰ç­–ç•¥å¤ªç²—æš´**  
   æˆ‘ä¸€å¼€å§‹ç›´æ¥æŒ‰ 500 å­—ç¬¦ç¡¬åˆ‡ï¼Œç»“æœæŠŠå¾ˆå¤šæœ‰æ„ä¹‰çš„æ®µè½åˆ‡æ–­äº†ï¼š
   ```
   åŸæ–‡ï¼š
   "Golang çš„å¹¶å‘æ¨¡å‹åŸºäº goroutine å’Œ channelã€‚goroutine æ˜¯è½»é‡çº§çº¿ç¨‹..."
   
   åˆ‡ç‰‡åï¼š
   Chunk 1: "Golang çš„å¹¶å‘æ¨¡å‹åŸºäº goroutine å’Œ chan"
   Chunk 2: "nelã€‚goroutine æ˜¯è½»é‡çº§çº¿ç¨‹..."
   ```
   è¿™æ · Embedding å‡ºæ¥çš„å‘é‡è¯­ä¹‰å°±æ–­äº†ã€‚

2. **æ²¡æœ‰è¿‡æ»¤ä½åˆ†æ•°ç»“æœ**  
   å³ä½¿æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ†æ•°å¾ˆä½ï¼ˆä¸ç›¸å…³ï¼‰ï¼Œæˆ‘ä¹Ÿç…§æ ·æ‰”ç»™ LLMï¼Œå¯¼è‡´ç”Ÿæˆçš„å›ç­”è´¨é‡å¾ˆå·®ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

```go
// 1. æ”¹è¿› Chunking ç­–ç•¥ï¼šæŒ‰æ®µè½ + ä¿ç•™ä¸Šä¸‹æ–‡
func smartChunk(content string, maxSize int) []string {
    // å…ˆæŒ‰æ®µè½åˆ†å‰²
    paragraphs := strings.Split(content, "\n\n")
    
    var chunks []string
    var currentChunk string
    
    for _, para := range paragraphs {
        // å¦‚æœåŠ ä¸Šè¿™æ®µè¿˜ä¸è¶…è¿‡ maxSizeï¼Œå°±åˆå¹¶
        if len(currentChunk) + len(para) < maxSize {
            currentChunk += para + "\n\n"
        } else {
            if currentChunk != "" {
                chunks = append(chunks, currentChunk)
            }
            currentChunk = para + "\n\n"
        }
    }
    
    if currentChunk != "" {
        chunks = append(chunks, currentChunk)
    }
    
    return chunks
}

// 2. è¿‡æ»¤ä½åˆ†æ•°ç»“æœ
func (r *RAGPipeline) Search(ctx context.Context, query string) ([]Document, error) {
    results, err := r.vectorDB.Search(ctx, queryVector, 10)
    if err != nil {
        return nil, err
    }
    
    // è¿‡æ»¤æ‰åˆ†æ•°ä½äº 0.7 çš„ç»“æœ
    var filtered []Document
    for _, doc := range results {
        if doc.Score >= 0.7 {  // âœ… åŠ è¿™ä¸ªé˜ˆå€¼åˆ¤æ–­
            filtered = append(filtered, doc)
        }
    }
    
    // å¦‚æœä¸€ä¸ªç›¸å…³æ–‡æ¡£éƒ½æ²¡æœ‰ï¼Œç›´æ¥è¿”å›"æˆ‘ä¸çŸ¥é“"
    if len(filtered) == 0 {
        return nil, ErrNoRelevantDocuments
    }
    
    return filtered, nil
}
```

**æ•™è®­**ï¼š  
- Chunking è¦ä¿ç•™è¯­ä¹‰å®Œæ•´æ€§ï¼Œä¸èƒ½ç¡¬åˆ‡  
- ä¸€å®šè¦è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œå®å¯å›ç­”"ä¸çŸ¥é“"ï¼Œä¹Ÿä¸è¦èƒ¡ä¹±å›ç­”

---

### å‘ 4ï¼šOpenAI API å¶å°”è¶…æ—¶ï¼Œæ•´ä¸ªæµç¨‹å¡æ­»

**ç°è±¡**ï¼š  
ç³»ç»Ÿè·‘ç€è·‘ç€ï¼Œçªç„¶å¡ä½ä¸åŠ¨äº†ï¼Œæ—¥å¿—åœåœ¨ï¼š
```
[INFO] Calling OpenAI API for embedding...
```

**åŸå› **ï¼š  
æˆ‘æ²¡ç»™ OpenAI API è°ƒç”¨è®¾ç½®è¶…æ—¶ï¼Œç½‘ç»œä¸€æŠ–åŠ¨å°±å¡æ­»ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```go
// âŒ é”™è¯¯çš„å†™æ³•ï¼šæ²¡æœ‰è¶…æ—¶æ§åˆ¶
func (e *EmbeddingService) Generate(ctx context.Context, text string) ([]float32, error) {
    resp, err := e.client.CreateEmbeddings(ctx, openai.EmbeddingRequest{
        Model: openai.AdaEmbeddingV2,
        Input: []string{text},
    })
    // ...
}

// âœ… æ­£ç¡®çš„å†™æ³•ï¼šåŠ ä¸Šè¶…æ—¶å’Œé‡è¯•
func (e *EmbeddingService) Generate(ctx context.Context, text string) ([]float32, error) {
    // 1. è®¾ç½® 10 ç§’è¶…æ—¶
    ctx, cancel := context.WithTimeout(ctx, 10*time.Second)
    defer cancel()
    
    // 2. æœ€å¤šé‡è¯• 3 æ¬¡
    var resp openai.EmbeddingResponse
    var err error
    
    for i := 0; i < 3; i++ {
        resp, err = e.client.CreateEmbeddings(ctx, openai.EmbeddingRequest{
            Model: openai.AdaEmbeddingV2,
            Input: []string{text},
        })
        
        if err == nil {
            break  // æˆåŠŸå°±é€€å‡º
        }
        
        log.Printf("é‡è¯• %d/3: %v", i+1, err)
        time.Sleep(time.Second * 2)  // ç­‰ 2 ç§’å†é‡è¯•
    }
    
    if err != nil {
        return nil, fmt.Errorf("ç”Ÿæˆ embedding å¤±è´¥ï¼ˆå·²é‡è¯•3æ¬¡ï¼‰: %w", err)
    }
    
    return resp.Data[0].Embedding, nil
}
```

**æ•™è®­**ï¼š  
- **ä»»ä½•å¤–éƒ¨ API è°ƒç”¨ï¼Œéƒ½è¦åŠ è¶…æ—¶å’Œé‡è¯•**  
- OpenAI API å¶å°”ä¼šæŠ½é£ï¼Œé‡è¯•æœºåˆ¶æ˜¯å¿…é¡»çš„

---

### å‘ 5ï¼šç”Ÿäº§ç¯å¢ƒæˆæœ¬å¤±æ§ï¼Œä¸€å¤©çƒ§äº† $50

**ç°è±¡**ï¼š  
RAG ç³»ç»Ÿä¸Šçº¿ç¬¬ 3 å¤©ï¼Œæ”¶åˆ° OpenAI è´¦å•è­¦å‘Šé‚®ä»¶ï¼š"Your usage has exceeded $50 in the last 24 hours"ã€‚

**æ’æŸ¥è¿‡ç¨‹**ï¼š  
æˆ‘æŸ¥äº†ä¸€ä¸‹ API è°ƒç”¨æ—¥å¿—ï¼Œå‘ç°ï¼š
- Embedding è°ƒç”¨ï¼š2000 æ¬¡/å¤©ï¼ˆæ­£å¸¸ï¼‰
- **GPT-4 è°ƒç”¨ï¼š12000 æ¬¡/å¤©**ï¼ˆä¸æ­£å¸¸ï¼ï¼‰

åŸæ¥æ˜¯æˆ‘æ²¡åš **ç¼“å­˜**ï¼ŒåŒæ ·çš„é—®é¢˜è¢«ç”¨æˆ·åå¤é—®ï¼Œç³»ç»Ÿæ¯æ¬¡éƒ½è°ƒç”¨ GPT-4 é‡æ–°ç”Ÿæˆç­”æ¡ˆã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```go
// å¢åŠ ç¼“å­˜å±‚ï¼ˆç”¨ Redisï¼‰
type CachedRAG struct {
    rag   *RAGPipeline
    cache *redis.Client
}

func (c *CachedRAG) Query(ctx context.Context, question string) (string, error) {
    // 1. å…ˆæŸ¥ç¼“å­˜
    cacheKey := "rag:answer:" + hashQuestion(question)
    cached, err := c.cache.Get(ctx, cacheKey).Result()
    if err == nil {
        log.Printf("ç¼“å­˜å‘½ä¸­: %s", question)
        return cached, nil
    }
    
    // 2. ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨ RAG
    answer, err := c.rag.Query(ctx, question)
    if err != nil {
        return "", err
    }
    
    // 3. å†™å…¥ç¼“å­˜ï¼ˆTTL = 1 å°æ—¶ï¼‰
    c.cache.Set(ctx, cacheKey, answer, time.Hour)
    
    return answer, nil
}

func hashQuestion(q string) string {
    h := sha256.Sum256([]byte(strings.ToLower(q)))
    return hex.EncodeToString(h[:])
}
```

**æˆæœ¬å¯¹æ¯”ï¼ˆåŠ ç¼“å­˜åï¼‰**ï¼š

| ç»´åº¦ | åŠ ç¼“å­˜å‰ | åŠ ç¼“å­˜å | èŠ‚çœ |
|------|----------|----------|------|
| GPT-4 è°ƒç”¨æ¬¡æ•°/å¤© | 12000 | 3000 | 75% |
| æ—¥å‡æˆæœ¬ | $50 | $12 | 76% |
| å¹³å‡å“åº”æ—¶é—´ | 2.5s | 0.8s | 68% |

ï¼ˆ**è¿™é‡Œåç»­è¡¥ä¸€å¼ æˆªå›¾ï¼šGrafana ç›‘æ§é¢æ¿ï¼Œæ˜¾ç¤ºç¼“å­˜å‘½ä¸­ç‡ + æˆæœ¬è¶‹åŠ¿å›¾**ï¼‰

**æ•™è®­**ï¼š  
- **ç”Ÿäº§ç¯å¢ƒå¿…é¡»åŠ ç¼“å­˜ï¼Œä¸ç„¶æˆæœ¬ä¼šå¤±æ§**  
- ç›‘æ§ API è°ƒç”¨é‡å’Œæˆæœ¬ï¼Œè®¾ç½®å‘Šè­¦é˜ˆå€¼

---

## ğŸ“ æœ€ä½³å®è·µæ€»ç»“

### âœ… DO

1. **åˆç†è®¾ç½® Chunk Size**ï¼š
   - æŠ€æœ¯æ–‡æ¡£ï¼š300-500 å­—ç¬¦
   - å¯¹è¯æ•°æ®ï¼š200-300 å­—ç¬¦
   - é•¿ç¯‡æ–‡ç« ï¼š500-800 å­—ç¬¦

2. **æ·»åŠ å…ƒæ•°æ®**ï¼š
   - æ–‡æ¡£æ¥æºã€æ—¶é—´æˆ³ã€åˆ†ç±»
   - ä¾¿äºè¿‡æ»¤å’Œè¿½æº¯

3. **ç›‘æ§æˆæœ¬**ï¼š
   - è®°å½• token ä½¿ç”¨é‡
   - ä½¿ç”¨ç¼“å­˜å‡å°‘ API è°ƒç”¨

4. **æµ‹è¯•å¬å›è´¨é‡**ï¼š
   - å‡†å¤‡æµ‹è¯•é›†
   - è®¡ç®— MRRã€NDCG ç­‰æŒ‡æ ‡

### âŒ DON'T

1. ä¸è¦ç›²ç›®å¢åŠ  topKï¼ˆæˆæœ¬é«˜ï¼Œå™ªéŸ³å¤šï¼‰
2. ä¸è¦å¿½ç•¥é”™è¯¯å¤„ç†ï¼ˆAPI è°ƒç”¨å¯èƒ½å¤±è´¥ï¼‰
3. ä¸è¦ç¡¬ç¼–ç  promptï¼ˆä½¿ç”¨é…ç½®æ–‡ä»¶ç®¡ç†ï¼‰
4. ä¸è¦å¿½ç•¥å®‰å…¨æ€§ï¼ˆAPI Key ç®¡ç†ã€è¾“å…¥éªŒè¯ï¼‰

## ğŸ”— ç›¸å…³èµ„æº

- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs)
- [Qdrant å®˜æ–¹æ–‡æ¡£](https://qdrant.tech/documentation/)
- [go-openai GitHub](https://github.com/sashabaranov/go-openai)
- [LangChain Go](https://github.com/tmc/langchaingo)

## ğŸ“ æ€»ç»“

æœ¬æ–‡è¯¦ç»†ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ Golang æ„å»ºä¸€ä¸ªå®Œæ•´çš„ RAG ç³»ç»Ÿï¼Œä»åŸºç¡€æ¶æ„åˆ°ç”Ÿäº§ä¼˜åŒ–éƒ½æœ‰æ¶‰åŠã€‚RAG æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œå»ºè®®æŒç»­å…³æ³¨æœ€æ–°è¿›å±•ï¼š

- **GraphRAG**ï¼šåŸºäºçŸ¥è¯†å›¾è°±çš„æ£€ç´¢
- **Self-RAG**ï¼šè‡ªæˆ‘åæ€çš„ RAG ç³»ç»Ÿ
- **Adaptive RAG**ï¼šæ ¹æ®æŸ¥è¯¢è‡ªé€‚åº”é€‰æ‹©ç­–ç•¥

å¸Œæœ›è¿™ç¯‡æ–‡ç« èƒ½å¸®åŠ©ä½ å¿«é€Ÿä¸Šæ‰‹ Golang + RAG å¼€å‘ï¼Œæ„å»ºå‡ºè‰²çš„ AI åº”ç”¨ï¼

---

**å…³é”®è¯**ï¼š#Golang #RAG #AI #LLM #VectorDatabase #OpenAI #Qdrant #SemanticSearch #Embedding #æ™ºèƒ½é—®ç­”

**ç›¸å…³æ–‡ç« æ¨è**ï¼š
- [Golang Socket é€šä¿¡æ¶æ„åˆ†æ](/zh/golang/Golang%20Socket%20%E9%80%9A%E4%BF%A1%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E6%9E%84%E5%BB%BA%E9%AB%98%E6%80%A7%E8%83%BD%E6%B8%B8%E6%88%8F%E6%9C%8D%E5%8A%A1%E5%99%A8)
- [åŸºäºGolangçš„é«˜æ€§èƒ½æ¸¸æˆæ¥å£è®¾è®¡](/zh/golang/%E5%9F%BA%E4%BA%8Egolang%20%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD%E6%B8%B8%E6%88%8F%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1)
- [Goå¼€å‘ç»ˆç«¯å°å·¥å…·](/zh/golang/Go%20%E5%BC%80%E5%8F%91%E7%BB%88%E7%AB%AF%E5%B0%8F%E5%B7%A5%E5%85%B7)

